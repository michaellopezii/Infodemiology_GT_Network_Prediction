{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from typing import Tuple, Dict\n",
    "import os\n",
    "import glob\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cohens_d(group1: np.ndarray, group2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Cohen's d effect size\n",
    "    \"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    \n",
    "    pooled_se = sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    \n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hodges_g(group1: np.ndarray, group2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Hodges' g effect size (corrected Cohen's d)\n",
    "    \"\"\"\n",
    "    d = calculate_cohens_d(group1, group2)\n",
    "    \n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    N = n1 + n2\n",
    "    correction_factor = (1 - (3 / (4 * N - 9)))\n",
    "    \n",
    "    return d * correction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(series1: np.ndarray, series2: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate all statistical measures between two series\n",
    "    \"\"\"\n",
    "    # Pearson correlation and p-value\n",
    "    pearson_corr, pearson_p = stats.pearsonr(series1, series2)\n",
    "    \n",
    "    # R-squared (coefficient of determination)\n",
    "    r_squared = pearson_corr ** 2\n",
    "    \n",
    "    # Kendall's tau and p-value\n",
    "    kendall_tau, kendall_p = stats.kendalltau(series1, series2)\n",
    "    \n",
    "    # Effect sizes\n",
    "    cohens_d = calculate_cohens_d(series1, series2)\n",
    "    hodges_g = calculate_hodges_g(series1, series2)\n",
    "    \n",
    "    return {\n",
    "        'pearson_correlation': pearson_corr,\n",
    "        'pearson_pvalue': pearson_p,\n",
    "        'r_squared': r_squared,\n",
    "        'kendall_tau': kendall_tau,\n",
    "        'kendall_pvalue': kendall_p,\n",
    "        'cohens_d': cohens_d,\n",
    "        'hodges_g': hodges_g\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pca_group_statistics(base_path: str, disease_dfs: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze statistical measures for PCA group metrics against disease cases\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Get all PCA group directories\n",
    "    pca_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d)) and d.startswith('pc')]\n",
    "    \n",
    "    for pca_dir in pca_dirs:\n",
    "        # Get group name without pc#_ prefix\n",
    "        group_name = '_'.join(pca_dir.split('_')[1:])\n",
    "        dir_path = os.path.join(base_path, pca_dir)\n",
    "        \n",
    "        print(f\"\\nProcessing PCA group: {group_name}\")\n",
    "        \n",
    "        # Process network density files\n",
    "        density_pattern = os.path.join(dir_path, \"netdense_*.csv\")\n",
    "        for file_path in glob.glob(density_pattern):\n",
    "            filename = os.path.basename(file_path)\n",
    "            thresh = filename.split('threshold_')[0].split('_')[-1]\n",
    "            window = filename.split('threshold_')[1].split('.')[0]\n",
    "            \n",
    "            metric_df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Skip if all zeros\n",
    "            if np.all(metric_df['network_density'] == 0):\n",
    "                print(f\"Skipping {filename} - network density contains all zeros\")\n",
    "                continue\n",
    "                \n",
    "            metric_df['date'] = pd.to_datetime(metric_df['date'])\n",
    "            \n",
    "            # Compare with each disease metric\n",
    "            for disease_name, disease_df in disease_dfs.items():\n",
    "                merged_df = pd.merge(metric_df, disease_df, on='date', how='inner')\n",
    "                \n",
    "                if len(merged_df) == 0:\n",
    "                    print(f\"No overlapping dates found for {filename} and {disease_name}\")\n",
    "                    continue\n",
    "                    \n",
    "                metric_series = merged_df['network_density'].values\n",
    "                disease_series = merged_df.iloc[:, -1].values\n",
    "                \n",
    "                try:\n",
    "                    # Calculate statistics\n",
    "                    stats_results = calculate_statistics(disease_series, metric_series)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'pca_group': group_name,\n",
    "                        'metric_type': 'Network Density',\n",
    "                        'threshold': thresh,\n",
    "                        'window': window,\n",
    "                        'comparison': disease_name,\n",
    "                        **stats_results\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {str(e)}\")\n",
    "                    import traceback\n",
    "                    print(traceback.format_exc())\n",
    "        \n",
    "        # Process clustering coefficient files\n",
    "        coeff_pattern = os.path.join(dir_path, \"cluscoeff_*.csv\")\n",
    "        for file_path in glob.glob(coeff_pattern):\n",
    "            filename = os.path.basename(file_path)\n",
    "            thresh = filename.split('threshold_')[0].split('_')[-1]\n",
    "            window = filename.split('threshold_')[1].split('.')[0]\n",
    "            \n",
    "            metric_df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Skip if all zeros\n",
    "            if np.all(metric_df['clustering_coefficient'] == 0):\n",
    "                print(f\"Skipping {filename} - clustering coefficient contains all zeros\")\n",
    "                continue\n",
    "                \n",
    "            metric_df['date'] = pd.to_datetime(metric_df['date'])\n",
    "            \n",
    "            # Compare with each disease metric\n",
    "            for disease_name, disease_df in disease_dfs.items():\n",
    "                merged_df = pd.merge(metric_df, disease_df, on='date', how='inner')\n",
    "                \n",
    "                if len(merged_df) == 0:\n",
    "                    print(f\"No overlapping dates found for {filename} and {disease_name}\")\n",
    "                    continue\n",
    "                    \n",
    "                metric_series = merged_df['clustering_coefficient'].values\n",
    "                disease_series = merged_df.iloc[:, -1].values\n",
    "                \n",
    "                try:\n",
    "                    # Calculate statistics\n",
    "                    stats_results = calculate_statistics(disease_series, metric_series)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'pca_group': group_name,\n",
    "                        'metric_type': 'Clustering Coefficient',\n",
    "                        'threshold': thresh,\n",
    "                        'window': window,\n",
    "                        'comparison': disease_name,\n",
    "                        **stats_results\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {str(e)}\")\n",
    "                    import traceback\n",
    "                    print(traceback.format_exc())\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df = pd.read_csv(\"../gt_stat_analysis/disease_confirmed_daily_cases.csv\")\n",
    "active_df = pd.read_csv(\"../gt_stat_analysis/disease_active_cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df['date'] = pd.to_datetime(confirmed_df['date'])\n",
    "active_df['date'] = pd.to_datetime(active_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmed_df['confirmed_cases'] = confirmed_df['confirmed_cases'] / 1000\n",
    "active_df['active_cases'] = active_df['active_cases'] / 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dfs = {\n",
    "    'Confirmed Cases': confirmed_df,\n",
    "    'Active Cases': active_df\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../gt_netdense_cluscoeff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing PCA group: MSVFaceWearing&Others-0.5\n",
      "Skipping netdense_MSVFaceWearing&Others-0.5_0.8threshold_30day.csv - network density contains all zeros\n",
      "Skipping cluscoeff_MSVFaceWearing&Others-0.5_0.8threshold_15day.csv - clustering coefficient contains all zeros\n",
      "Skipping cluscoeff_MSVFaceWearing&Others-0.5_0.8threshold_30day.csv - clustering coefficient contains all zeros\n",
      "Skipping cluscoeff_MSVFaceWearing&Others-0.5_0.6threshold_30day.csv - clustering coefficient contains all zeros\n",
      "\n",
      "Processing PCA group: RSVSymptoms&NewNormalProtocols1-0.6\n",
      "\n",
      "Processing PCA group: RSVFaceWearing&Others-0.5\n",
      "Skipping netdense_RSVFaceWearing&Others-0.5_0.8threshold_30day.csv - network density contains all zeros\n",
      "Skipping cluscoeff_RSVFaceWearing&Others-0.5_0.8threshold_15day.csv - clustering coefficient contains all zeros\n",
      "Skipping cluscoeff_RSVFaceWearing&Others-0.5_0.6threshold_30day.csv - clustering coefficient contains all zeros\n",
      "Skipping cluscoeff_RSVFaceWearing&Others-0.5_0.8threshold_30day.csv - clustering coefficient contains all zeros\n",
      "\n",
      "Processing PCA group: MSVSymptoms-0.5\n",
      "\n",
      "Processing PCA group: RSVSymptoms&NewNormalProtocols-0.5\n",
      "\n",
      "Processing PCA group: RSVSymptoms&NewNormalProtocols2-0.6\n",
      "Skipping netdense_RSVSymptoms&NewNormalProtocols2-0.6_0.8threshold_30day.csv - network density contains all zeros\n",
      "Skipping cluscoeff_RSVSymptoms&NewNormalProtocols2-0.6_0.6threshold_30day.csv - clustering coefficient contains all zeros\n",
      "Skipping cluscoeff_RSVSymptoms&NewNormalProtocols2-0.6_0.8threshold_30day.csv - clustering coefficient contains all zeros\n",
      "Skipping cluscoeff_RSVSymptoms&NewNormalProtocols2-0.6_0.8threshold_15day.csv - clustering coefficient contains all zeros\n",
      "\n",
      "Processing PCA group: MSVSymptoms&NewNormalProtocols-0.6\n",
      "Skipping cluscoeff_MSVSymptoms&NewNormalProtocols-0.6_0.8threshold_30day.csv - clustering coefficient contains all zeros\n",
      "Skipping cluscoeff_MSVSymptoms&NewNormalProtocols-0.6_0.8threshold_15day.csv - clustering coefficient contains all zeros\n"
     ]
    }
   ],
   "source": [
    "all_results = analyze_pca_group_statistics(base_path, disease_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_csv('pca_statistical_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "\n",
      "Clustering Coefficient vs Active Cases:\n",
      "Average Results:\n",
      "Pearson Correlation: -0.108\n",
      "Pearson P-value: 0.093\n",
      "R-squared: 0.029\n",
      "Kendall's Tau: -0.116\n",
      "Kendall P-value: 0.117\n",
      "Cohen's d: 1.257\n",
      "Hodges' g: 1.256\n",
      "\n",
      "Clustering Coefficient vs Confirmed Cases:\n",
      "Average Results:\n",
      "Pearson Correlation: -0.081\n",
      "Pearson P-value: 0.121\n",
      "R-squared: 0.018\n",
      "Kendall's Tau: -0.116\n",
      "Kendall P-value: 0.136\n",
      "Cohen's d: 1.340\n",
      "Hodges' g: 1.338\n",
      "\n",
      "Network Density vs Active Cases:\n",
      "Average Results:\n",
      "Pearson Correlation: -0.021\n",
      "Pearson P-value: 0.199\n",
      "R-squared: 0.037\n",
      "Kendall's Tau: -0.029\n",
      "Kendall P-value: 0.166\n",
      "Cohen's d: 0.224\n",
      "Hodges' g: 0.224\n",
      "\n",
      "Network Density vs Confirmed Cases:\n",
      "Average Results:\n",
      "Pearson Correlation: -0.016\n",
      "Pearson P-value: 0.199\n",
      "R-squared: 0.028\n",
      "Kendall's Tau: -0.048\n",
      "Kendall P-value: 0.145\n",
      "Cohen's d: 1.133\n",
      "Hodges' g: 1.132\n",
      "\n",
      "Top 10 strongest correlations (by absolute Pearson correlation):\n",
      "                               pca_group             metric_type threshold  \\\n",
      "58             RSVFaceWearing&Others-0.5         Network Density       0.6   \n",
      "59             RSVFaceWearing&Others-0.5         Network Density       0.6   \n",
      "61             RSVFaceWearing&Others-0.5         Network Density       0.5   \n",
      "60             RSVFaceWearing&Others-0.5         Network Density       0.5   \n",
      "145  RSVSymptoms&NewNormalProtocols2-0.6         Network Density       0.6   \n",
      "144  RSVSymptoms&NewNormalProtocols2-0.6         Network Density       0.6   \n",
      "147  RSVSymptoms&NewNormalProtocols2-0.6         Network Density       0.5   \n",
      "53   RSVSymptoms&NewNormalProtocols1-0.6  Clustering Coefficient       0.8   \n",
      "63             RSVFaceWearing&Others-0.5         Network Density       0.4   \n",
      "33   RSVSymptoms&NewNormalProtocols1-0.6         Network Density       0.8   \n",
      "\n",
      "    window       comparison  pearson_correlation  pearson_pvalue  \n",
      "58   30day  Confirmed Cases             0.593628    1.810603e-33  \n",
      "59   30day     Active Cases             0.592217    2.795740e-33  \n",
      "61   30day     Active Cases             0.531421    5.887572e-26  \n",
      "60   30day  Confirmed Cases             0.478368    1.127655e-20  \n",
      "145  30day     Active Cases             0.474211    2.682112e-20  \n",
      "144  30day  Confirmed Cases             0.458443    6.456587e-19  \n",
      "147  30day     Active Cases             0.338776    1.705043e-10  \n",
      "53   30day     Active Cases            -0.325115    9.777932e-10  \n",
      "63   30day     Active Cases             0.297698    2.525052e-08  \n",
      "33   30day     Active Cases            -0.283455    1.202142e-07  \n"
     ]
    }
   ],
   "source": [
    "grouped_results = all_results.groupby(['metric_type', 'comparison'])\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "for (metric, comparison), group in grouped_results:\n",
    "    print(f\"\\n{metric} vs {comparison}:\")\n",
    "    print(\"Average Results:\")\n",
    "    print(f\"Pearson Correlation: {group['pearson_correlation'].mean():.3f}\")\n",
    "    print(f\"Pearson P-value: {group['pearson_pvalue'].mean():.3f}\")\n",
    "    print(f\"R-squared: {group['r_squared'].mean():.3f}\")\n",
    "    print(f\"Kendall's Tau: {group['kendall_tau'].mean():.3f}\")\n",
    "    print(f\"Kendall P-value: {group['kendall_pvalue'].mean():.3f}\")\n",
    "    print(f\"Cohen's d: {group['cohens_d'].mean():.3f}\")\n",
    "    print(f\"Hodges' g: {group['hodges_g'].mean():.3f}\")\n",
    "\n",
    "# Display top correlations\n",
    "print(\"\\nTop 10 strongest correlations (by absolute Pearson correlation):\")\n",
    "top_correlations = all_results.copy()\n",
    "top_correlations['abs_correlation'] = abs(top_correlations['pearson_correlation'])\n",
    "top_correlations = top_correlations.sort_values('abs_correlation', ascending=False)\n",
    "print(top_correlations.head(10)[['pca_group', 'metric_type', 'threshold', 'window', \n",
    "                                'comparison', 'pearson_correlation', 'pearson_pvalue']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
